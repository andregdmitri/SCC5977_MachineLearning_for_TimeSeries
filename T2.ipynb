{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCC5977 - Aprendizado de Máquina para Séries Temporais (2024)\n",
    "\n",
    "## Grupo\n",
    "> André Guarnier De Mitri - 11395579 \\\n",
    "> Fabio Cavaleti - 11200550\\\n",
    "> Giovani Decico Lucafó - 10288779\n",
    "\n",
    "## Problema\n",
    "Incentia 11k euclidiana vs ddtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Module.train() got an unexpected keyword argument 'steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 158\u001b[0m\n\u001b[0;32m    153\u001b[0m classifier \u001b[38;5;241m=\u001b[39m KANClassifier(\n\u001b[0;32m    154\u001b[0m     width\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m30\u001b[39m], steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    155\u001b[0m )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Train and evaluate the model\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m train_acc, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_and_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test_encoded\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Decode the integer labels if needed\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 111\u001b[0m, in \u001b[0;36mKANClassifier.fit_and_validate\u001b[1;34m(self, xtrain, ytrain, xval, yval)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_acc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_train_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_test_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Module.train() got an unexpected keyword argument 'steps'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Tuple\n",
    "from aeon.datasets import load_from_tsfile\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import check_random_state\n",
    "from kan import KAN  # Ensure KAN is correctly installed and available\n",
    "\n",
    "\n",
    "class KANClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: list,\n",
    "        output_dir: str = \"./\",\n",
    "        steps: int = 20,\n",
    "        k: int = 3,\n",
    "        grid: int = 5,\n",
    "        random_state: int = None,\n",
    "    ):\n",
    "        \"\"\"KAN Time Series Classifier.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        width : list\n",
    "            The width of the KAN layers.\n",
    "        output_dir : str, default = \"./\"\n",
    "            The output directory.\n",
    "        steps : int, default = 20\n",
    "            The number of optimization steps.\n",
    "        k : int, default = 3\n",
    "            The order of piecewise polynomial.\n",
    "        grid : int, default = 5\n",
    "            The number of grid intervals.\n",
    "        random_state : int, default = None\n",
    "            The random state for the initial seed.\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.output_dir = output_dir\n",
    "        self.steps = steps\n",
    "        self.k = k\n",
    "        self.grid = grid\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _train_acc(self):\n",
    "        return torch.mean(\n",
    "            (\n",
    "                torch.argmax(self.model(self.dataset[\"train_input\"]), dim=1)\n",
    "                == self.dataset[\"train_label\"]\n",
    "            ).float()\n",
    "        )\n",
    "\n",
    "    def _test_acc(self):\n",
    "        return torch.mean(\n",
    "            (\n",
    "                torch.argmax(self.model(self.dataset[\"test_input\"]), dim=1)\n",
    "                == self.dataset[\"test_label\"]\n",
    "            ).float()\n",
    "        )\n",
    "\n",
    "def fit_and_validate(\n",
    "    self, xtrain: np.ndarray, ytrain: np.ndarray, xval: np.ndarray, yval: np.ndarray\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Training and Evaluating the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xtrain : np.ndarray of shape (n_instances, 1, n_timepoints)\n",
    "        The input time series for training.\n",
    "    ytrain : np.ndarray of shape (n_instances,)\n",
    "        The labels of the training samples.\n",
    "    xval : np.ndarray of shape (n_instances, 1, n_timepoints)\n",
    "        The input time series for validation.\n",
    "    yval : np.ndarray of shape (n_instances,)\n",
    "        The labels of the validation samples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        The accuracies on both train and validation sets.\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    self.device = \"cpu\"\n",
    "\n",
    "    # Prepare datasets\n",
    "    self.dataset = {\n",
    "        \"train_input\": torch.from_numpy(xtrain).float().to(self.device),\n",
    "        \"train_label\": torch.from_numpy(ytrain).long().to(self.device),\n",
    "        \"test_input\": torch.from_numpy(xval).float().to(self.device),\n",
    "        \"test_label\": torch.from_numpy(yval).long().to(self.device),\n",
    "    }\n",
    "\n",
    "    # Configure model dimensions\n",
    "    _, _, self.length_TS = xtrain.shape  # Number of time points\n",
    "    self.n_classes = len(np.unique(ytrain))\n",
    "\n",
    "    # Define KAN model layers\n",
    "    self.width_ = [self.length_TS] + self.width + [self.n_classes]\n",
    "\n",
    "    # Instantiate KAN model\n",
    "    self.model = KAN(\n",
    "        width=self.width_,\n",
    "        grid=self.grid,\n",
    "        k=self.k,\n",
    "        seed=self.random_state,\n",
    "        device=self.device,\n",
    "    )\n",
    "    self.model.to(self.device)\n",
    "\n",
    "    # Train the model\n",
    "    self.results = self.model.train(\n",
    "        self.dataset,\n",
    "        steps=self.steps,\n",
    "        metrics=(self._train_acc, self._test_acc),\n",
    "        loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "        device=self.device,\n",
    "    )\n",
    "\n",
    "    return self.results[\"_train_acc\"][-1], self.results[\"_test_acc\"][-1]\n",
    "\n",
    "    def get_symbolic_function(self):\n",
    "        \"\"\"Generate symbolic functions for the learned model.\"\"\"\n",
    "        lib = [\n",
    "            \"x\",\n",
    "            \"x^2\",\n",
    "            \"x^3\",\n",
    "            \"x^4\",\n",
    "            \"exp\",\n",
    "            \"log\",\n",
    "            \"sqrt\",\n",
    "            \"tanh\",\n",
    "            \"sin\",\n",
    "            \"tan\",\n",
    "            \"abs\",\n",
    "        ]\n",
    "        self.model.auto_symbolic(lib=lib)\n",
    "        self.formulas = self.model.symbolic_formula()[0]\n",
    "\n",
    "        return [_formula for _formula in self.formulas]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load training and testing datasets\n",
    "    X_train, y_train = load_from_tsfile(\"./data/ts_files/train.ts\")\n",
    "    X_test, y_test = load_from_tsfile(\"./data/ts_files/test.ts\")\n",
    "\n",
    "    # Encode string labels into integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "    # Instantiate classifier\n",
    "    classifier = KANClassifier(\n",
    "        width=[50, 30], steps=20, k=3, grid=5, random_state=42\n",
    "    )\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    train_acc, test_acc = classifier.fit_and_validate(\n",
    "        xtrain=X_train, ytrain=y_train_encoded,\n",
    "        xval=X_test, yval=y_test_encoded\n",
    "    )\n",
    "\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Decode the integer labels if needed\n",
    "    class_labels = label_encoder.inverse_transform(range(len(label_encoder.classes_)))\n",
    "    print(f\"Class Labels: {class_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 1, 137)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 31\u001b[0m\n\u001b[0;32m     24\u001b[0m dataset \u001b[38;5;241m=\u001b[39m create_dataset(\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: torch\u001b[38;5;241m.\u001b[39mtensor([label_mapping[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m y_train], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[0;32m     26\u001b[0m     n_var\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],  \u001b[38;5;66;03m# Number of variables (features)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Pass the dataset to the model\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Plot the model\u001b[39;00m\n\u001b[0;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[1;32mc:\\Users\\andre\\1JUPYTER\\SCC5977_MachineLearning_for_TimeSeries\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\1JUPYTER\\SCC5977_MachineLearning_for_TimeSeries\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\1JUPYTER\\SCC5977_MachineLearning_for_TimeSeries\\.conda\\Lib\\site-packages\\kan\\MultKAN.py:779\u001b[0m, in \u001b[0;36mMultKAN.forward\u001b[1;34m(self, x, singularity_avoiding, y_th)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, singularity_avoiding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, y_th\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.\u001b[39m):\n\u001b[0;32m    746\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;124;03m    forward pass\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;124;03m    >>> print(model(x, singularity_avoiding=True, y_th=1.))\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 779\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth_in[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# cache data\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "from kan import KAN\n",
    "from kan.utils import create_dataset\n",
    "import torch\n",
    "from aeon.datasets._data_loaders import load_from_tsfile\n",
    "\n",
    "# Set default data type and device\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Create a KAN: 2D inputs, 1D output, and 5 hidden neurons. Cubic spline (k=3), 5 grid intervals (grid=5).\n",
    "model = KAN(width=[2, 5, 1], grid=3, k=3, seed=42, device=device)\n",
    "\n",
    "# Load dataset\n",
    "X_train, y_train = load_from_tsfile(\"./data/ts_files/train.ts\")\n",
    "X_test, y_test = load_from_tsfile(\"./data/ts_files/test.ts\")\n",
    "\n",
    "# Map labels to integers\n",
    "unique_labels = set(y_train)\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "# Prepare the dataset using create_dataset\n",
    "# The lambda function maps the label values to their integer equivalents\n",
    "dataset = create_dataset(\n",
    "    lambda x: torch.tensor([label_mapping[label] for label in y_train], dtype=torch.long),\n",
    "    n_var=X_train.shape[1],  # Number of variables (features)\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Pass the dataset to the model\n",
    "model(dataset)\n",
    "\n",
    "# Plot the model\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "dataset['train_input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
