{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCC5977 - Aprendizado de Máquina para Séries Temporais (2024)\n",
    "\n",
    "## Grupo\n",
    "> André Guarnier De Mitri - 11395579 \\\n",
    "> Fabio Cavaleti - 11200550\\\n",
    "> Giovani Decico Lucafó - 10288779\n",
    "\n",
    "## Problema\n",
    "Incentia 11k euclidiana vs ddtw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste inicial: KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.06e-03 | test_loss: 3.61e+00 | reg: 1.37e+03 | : 100%|█| 100/100 [01:42<00:00,  1.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train Loss: 0.0011, Test Loss: 3.6124\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.4433\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from aeon.datasets import load_from_ts_file\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from kan import KAN\n",
    "\n",
    "# Load training and testing datasets\n",
    "if not os.path.exists(\"./data/ts_files/train.ts\") or not os.path.exists(\"./data/ts_files/test.ts\"):\n",
    "    raise FileNotFoundError(\"Train or test .ts files not found in the specified directory.\")\n",
    "\n",
    "X_train, y_train = load_from_ts_file(\"./data/ts_files/train.ts\")\n",
    "X_test, y_test = load_from_ts_file(\"./data/ts_files/test.ts\")\n",
    "\n",
    "# Encode string labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Set device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare data for KAN\n",
    "train_input = torch.from_numpy(X_train.squeeze(1)).float().to(device)\n",
    "train_label = torch.from_numpy(y_train_encoded).long().to(device)\n",
    "test_input = torch.from_numpy(X_test.squeeze(1)).float().to(device)\n",
    "test_label = torch.from_numpy(y_test_encoded).long().to(device)\n",
    "\n",
    "# Extract dimensions for KAN\n",
    "n_instances, n_timepoints = train_input.shape  # 6000, 137\n",
    "n_classes = len(np.unique(y_train_encoded))  # number of unique classes\n",
    "\n",
    "# Define the width of the KAN layers (adjusted for your data)\n",
    "width = [[n_timepoints, 0],\n",
    "         [50, 0],\n",
    "         [30, 0],\n",
    "         [n_classes, 0]]\n",
    "\n",
    "# Initialize the KAN model\n",
    "model = KAN(width=width, grid=5, k=3, seed=42, device=device)\n",
    "model.to(device)\n",
    "\n",
    "# Prepare dataset dictionary for KAN\n",
    "dataset = {\n",
    "    \"train_input\": train_input,\n",
    "    \"train_label\": train_label,\n",
    "    \"test_input\": test_input,\n",
    "    \"test_label\": test_label,\n",
    "}\n",
    "\n",
    "# Accuracy function\n",
    "def train_acc():\n",
    "    return torch.mean((torch.argmax(model(dataset['train_input']), dim=1) == dataset['train_label']).float())\n",
    "\n",
    "def test_acc():\n",
    "    return torch.mean((torch.argmax(model(dataset['test_input']), dim=1) == dataset['test_label']).float())\n",
    "\n",
    "\n",
    "# Train the model with accuracy and F1 score metrics\n",
    "results = model.fit(\n",
    "    dataset=dataset,\n",
    "    steps=100,\n",
    "    metrics=(train_acc, test_acc),\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    log=1,\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "train_loss, test_loss = results[\"train_loss\"][-1], results[\"test_loss\"][-1]\n",
    "train_accuracy, test_accuracy = results[\"train_acc\"][-1], results[\"test_acc\"][-1]\n",
    "\n",
    "print(f\"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN + KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\andre\\anaconda3\\envs\\pykan\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\andre\\1JUPYTER\\SCC5977_MachineLearning_for_TimeSeries\\experiments exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | FCNClassifier    | 281 K  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.126     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\andre\\anaconda3\\envs\\pykan\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   7%|▋         | 7/94 [00:00<00:03, 26.02it/s, v_num=0, train_loss_step=1.130, train_accuracy_step=0.281, train_f1_step=0.205]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\envs\\pykan\\lib\\site-packages\\torch\\nn\\modules\\conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:1037.)\n",
      "  return F.conv1d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 94/94 [00:24<00:00,  3.91it/s, v_num=0, train_loss_step=0.762, train_accuracy_step=0.729, train_f1_step=0.704, train_loss_epoch=0.769, train_accuracy_epoch=0.704, train_f1_epoch=0.702]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 94/94 [00:24<00:00,  3.91it/s, v_num=0, train_loss_step=0.762, train_accuracy_step=0.729, train_f1_step=0.704, train_loss_epoch=0.769, train_accuracy_epoch=0.704, train_f1_epoch=0.702]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from models.fcn import FCNClassifier\n",
    "from utils import TimeSeriesClassifier, TimeSeriesDataset\n",
    "from kan import KAN\n",
    "from aeon.datasets import load_from_ts_file\n",
    "\n",
    "# Load time series data\n",
    "X_train, y_train = load_from_ts_file(\"./data/ts_files/train.ts\")\n",
    "X_test, y_test = load_from_ts_file(\"./data/ts_files/test.ts\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Infer sequence length and dimensions\n",
    "sequence_len = X_train.shape[-1]\n",
    "dimension_num = X_train.shape[1] if len(X_train.shape) > 1 else 1\n",
    "\n",
    "# Datasets\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train_encoded)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test_encoded)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# FCNClassifier Model\n",
    "activation_fn = nn.ReLU()\n",
    "fcn_model = FCNClassifier(\n",
    "    dimension_num=dimension_num,\n",
    "    activation=activation_fn,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "# Wrap FCNClassifier into LightningModule\n",
    "optimizer = torch.optim.Adadelta(fcn_model.parameters(), lr=1e-3, eps=1e-8)\n",
    "model_classifier = TimeSeriesClassifier(model=fcn_model, optimizer=optimizer)\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"experiments\",\n",
    "    filename=\"cls_fcn\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"train_f1\",\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=-1,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "# Train the FCNClassifier model\n",
    "trainer.fit(model_classifier, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.08e-01 | test_loss: 1.75e+00 | reg: 9.69e+02 | : 100%|█| 50/50 [01:13<00:00,  1.47s/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Train Loss: 0.1082, Test Loss: 1.7453\n",
      "Train Accuracy: 0.9982, Test Accuracy: 0.5067\n"
     ]
    }
   ],
   "source": [
    "from models.fcn import GAP1d\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fcn_model.to(device)\n",
    "def get_embeddings(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)  # Ensure both data and labels are on the same device\n",
    "            \n",
    "            x = data  # Initialize x with the input data\n",
    "            for layer in model.layers:\n",
    "                x = layer(x)\n",
    "                if isinstance(layer, GAP1d):  # Check if the layer is a GAP1d layer\n",
    "                    embeddings = x  # Capture the output from GAP1d layer (before flattening)\n",
    "                    break  # Exit the loop after capturing the embeddings\n",
    "\n",
    "            embeddings_list.append(embeddings.cpu())  # Store embeddings (move to CPU if necessary)\n",
    "            labels_list.append(labels.cpu())  # Store labels (move to CPU if necessary)\n",
    "\n",
    "    embeddings = torch.cat(embeddings_list, dim=0)  # Concatenate embeddings across batches\n",
    "    labels = torch.cat(labels_list, dim=0)  # Concatenate labels across batches\n",
    "    \n",
    "    return embeddings, labels\n",
    "\n",
    "# Get the embeddings from the FCN model\n",
    "train_embeddings, train_labels = get_embeddings(fcn_model, train_loader, device)\n",
    "test_embeddings, test_labels = get_embeddings(fcn_model, test_loader, device)\n",
    "\n",
    "# Move the embeddings and labels to the correct device (if necessary)\n",
    "train_input = train_embeddings.to(device)\n",
    "test_input = test_embeddings.to(device)\n",
    "train_label = train_labels.to(device)\n",
    "test_label = test_labels.to(device)\n",
    "\n",
    "# Define KAN model input dimensions\n",
    "n_instances, embedding_size = train_input.shape\n",
    "n_classes = len(np.unique(train_labels))  # Number of classes based on the training labels\n",
    "\n",
    "width = [[embedding_size, 0],\n",
    "         [50, 0],\n",
    "         [30, 0],\n",
    "         [n_classes, 0]]\n",
    "\n",
    "# Initialize KAN model\n",
    "kan_model = KAN(width=width, grid=5, k=3, seed=42, device=device)\n",
    "kan_model.to(device)\n",
    "\n",
    "# Prepare dataset for KAN (format for KAN model)\n",
    "dataset = {\n",
    "    \"train_input\": train_input,\n",
    "    \"train_label\": train_label,\n",
    "    \"test_input\": test_input,\n",
    "    \"test_label\": test_label,\n",
    "}\n",
    "\n",
    "# Define accuracy functions for KAN\n",
    "def train_acc():\n",
    "    return torch.mean((torch.argmax(kan_model(dataset[\"train_input\"]), dim=1) == dataset[\"train_label\"]).float())\n",
    "\n",
    "def test_acc():\n",
    "    return torch.mean((torch.argmax(kan_model(dataset[\"test_input\"]), dim=1) == dataset[\"test_label\"]).float())\n",
    "\n",
    "# Train the KAN model\n",
    "kan_results = kan_model.fit(\n",
    "    dataset=dataset,\n",
    "    steps=50,\n",
    "    metrics=(train_acc, test_acc),\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    log=1,\n",
    ")\n",
    "\n",
    "# Evaluate the KAN model after training\n",
    "train_loss, test_loss = kan_results[\"train_loss\"][-1], kan_results[\"test_loss\"][-1]\n",
    "train_accuracy, test_accuracy = kan_results[\"train_acc\"][-1], kan_results[\"test_acc\"][-1]\n",
    "\n",
    "# Print results\n",
    "print(f\"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
