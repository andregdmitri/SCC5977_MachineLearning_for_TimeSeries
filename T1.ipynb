{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCC5977 - Aprendizado de Máquina para Séries Temporais (2024)\n",
    "\n",
    "## Grupo\n",
    "> André Guarnier De Mitri - 11395579 \\\n",
    "> Fabio \\\n",
    "> Giovanni\n",
    "\n",
    "## Problema\n",
    "Incentia 11k euclidiana vs ddtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERSÃO 1.0 SEM PROCESSAMENTO PARALELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6000 time series with shape (1, 137).\n",
      "Calculating Euclidean Distance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Euclidean Distance: 100%|██████████| 17997000/17997000 [20:18<00:00, 14773.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance completed in 1218.18 seconds.\n",
      "Calculating Derivative DTW Distance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Derivative DTW Distance:  13%|█▎        | 2251135/17997000 [16:23<1:52:56, 2323.64it/s]"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from aeon.distances import pairwise_distance, ddtw_distance\n",
    "import numpy as np\n",
    "from aeon.datasets import load_from_tsfile\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "def load_and_validate_data(file_path):\n",
    "    \"\"\"Load and validate time series data.\"\"\"\n",
    "    X, y = load_from_tsfile(full_file_path_and_name=file_path)\n",
    "    print(f\"Loaded {X.shape[0]} time series with shape {X.shape[1:]}.\")\n",
    "    return X\n",
    "\n",
    "\n",
    "def calculate_distances(X, metric_function, metric_name):\n",
    "    \"\"\"Calculate pairwise distances using the specified metric with progress tracking.\"\"\"\n",
    "    num_ts = X.shape[0]\n",
    "    total_combinations = (num_ts * (num_ts - 1)) // 2  # Number of combinations\n",
    "\n",
    "    print(f\"Calculating {metric_name}...\")\n",
    "    distances = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with tqdm(total=total_combinations, desc=metric_name) as pbar:\n",
    "        for (i, ts1), (j, ts2) in combinations(enumerate(X[:, 0]), 2):\n",
    "            distances.append((float(metric_function(ts1, ts2)), i, j))\n",
    "            pbar.update(1)  # Update the progress bar\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"{metric_name} completed in {elapsed_time:.2f} seconds.\")\n",
    "    return distances, elapsed_time\n",
    "\n",
    "def summarize_distances(distances, distance_type):\n",
    "    \"\"\"Summarize and print statistics for the given distances.\"\"\"\n",
    "    distances_only = [d[0] for d in distances]\n",
    "    smallest = min(distances, key=lambda x: x[0])\n",
    "    largest = max(distances, key=lambda x: x[0])\n",
    "    median_dist = np.median(distances_only)\n",
    "\n",
    "    print(f\"\\n{distance_type} Analysis:\")\n",
    "    print(f\"Median Distance: {median_dist:.4f}\")\n",
    "    print(f\"Smallest Distance: {smallest[0]:.4f} (between series {smallest[1]} and {smallest[2]})\")\n",
    "    print(f\"Largest Distance: {largest[0]:.4f} (between series {largest[1]} and {largest[2]})\")\n",
    "\n",
    "    return smallest, largest\n",
    "\n",
    "\n",
    "def plot_time_series_comparison(X, pair, title, axs):\n",
    "    \"\"\"Plot two time series with a title.\"\"\"\n",
    "    ts1, ts2 = X[pair[1], 0], X[pair[2], 0]\n",
    "    axs.plot(ts1, label=\"Time Series 1\")\n",
    "    axs.plot(ts2, label=\"Time Series 2\")\n",
    "    axs.set_title(title)\n",
    "    axs.legend()\n",
    "    axs.grid(True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    file_path = './data/ts_files/train.ts'\n",
    "    X = load_and_validate_data(file_path)\n",
    "\n",
    "    # Calculate distances\n",
    "    euclidean_distances, euclidean_time = calculate_distances(\n",
    "        X, lambda x, y: pairwise_distance(x, y, metric=\"euclidean\"), \"Euclidean Distance\"\n",
    "    )\n",
    "    ddtw_distances, ddtw_time = calculate_distances(X, ddtw_distance, \"Derivative DTW Distance\")\n",
    "\n",
    "    # Summarize distances\n",
    "    euclidean_smallest, euclidean_largest = summarize_distances(euclidean_distances, \"Euclidean Distance\")\n",
    "    ddtw_smallest, ddtw_largest = summarize_distances(ddtw_distances, \"Derivative DTW Distance\")\n",
    "\n",
    "    # Print time analysis\n",
    "    print(f\"\\nTiming Analysis:\")\n",
    "    print(f\"Euclidean Distance took {euclidean_time:.2f} seconds.\")\n",
    "    print(f\"Derivative DTW Distance took {ddtw_time:.2f} seconds.\")\n",
    "\n",
    "    # Plot the time series comparisons\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "    plot_time_series_comparison(X, euclidean_smallest, \"Smallest Euclidean Distance\", axs[0, 0])\n",
    "    plot_time_series_comparison(X, ddtw_smallest, \"Smallest DDTW Distance\", axs[0, 1])\n",
    "    plot_time_series_comparison(X, euclidean_largest, \"Largest Euclidean Distance\", axs[1, 0])\n",
    "    plot_time_series_comparison(X, ddtw_largest, \"Largest DDTW Distance\", axs[1, 1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similariedade por classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_class_similarities(X, y, metric_function, metric_name):\n",
    "    \"\"\"Calculate pairwise distances within sampled instances of each class.\"\"\"\n",
    "    unique_classes = np.unique(y)\n",
    "    class_samples = {}\n",
    "    class_distances = {}\n",
    "\n",
    "    for class_label in unique_classes:\n",
    "        # Filter indices for the current class\n",
    "        class_indices = np.where(y == class_label)[0]\n",
    "        \n",
    "        # Randomly sample 5 instances from the class\n",
    "        sampled_indices = sample(list(class_indices), min(5, len(class_indices)))\n",
    "        class_samples[class_label] = sampled_indices\n",
    "        \n",
    "        # Calculate distances within the sampled class\n",
    "        distances = []\n",
    "        for (i, ts1), (j, ts2) in combinations(enumerate(X[sampled_indices, 0]), 2):\n",
    "            distances.append(float(metric_function(ts1, ts2)))\n",
    "\n",
    "        class_distances[class_label] = distances\n",
    "\n",
    "    # Summarize results\n",
    "    for class_label, distances in class_distances.items():\n",
    "        if distances:\n",
    "            median_dist = np.median(distances)\n",
    "            mean_dist = np.mean(distances)\n",
    "            print(f\"\\nClass {class_label} ({metric_name}):\")\n",
    "            print(f\"  Median Distance: {median_dist:.4f}\")\n",
    "            print(f\"  Mean Distance: {mean_dist:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\nClass {class_label}: Insufficient data for calculation.\")\n",
    "\n",
    "    return class_samples, class_distances\n",
    "\n",
    "def main_similarity_analysis():\n",
    "    # Load data\n",
    "    file_path = './data/ts_files/train.ts'\n",
    "    X, y = load_from_tsfile(full_file_path_and_name=file_path)\n",
    "\n",
    "    # Analyze similarities for each class\n",
    "    print(\"\\n=== Similarity Analysis ===\")\n",
    "    \n",
    "    # Euclidean\n",
    "    calculate_class_similarities(\n",
    "        X, y,\n",
    "        lambda x, y: pairwise_distance(x, y, metric=\"euclidean\"),\n",
    "        \"Euclidean Distance\"\n",
    "    )\n",
    "\n",
    "    # Derivative DTW\n",
    "    calculate_class_similarities(\n",
    "        X, y,\n",
    "        ddtw_distance,\n",
    "        \"Derivative DTW Distance\"\n",
    "    )\n",
    "\n",
    "# Run the similarity analysis\n",
    "main_similarity_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalhos relacionados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritimos Utilizados\n",
    "> DDTW \\\n",
    "> Baseline Euclidiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodologia\n",
    "\n",
    "O conjunto de dados usado nesse cenário foi o Icentia11k, um banco de dados com sinais contínuos de ECG brutos, amostrados a 250Hz, abrangendo 11.000 pacientes e 2 bilhões de batimentos anotados.\n",
    "\n",
    "Por conta dos custos computacionais, limitamos nossa análise aos primeiros 1.000 pacientes. No entanto, embora todos os pacientes tivessem as localizações dos batimentos anotadas por especialistas, a maioria não tinha rótulos de classe ou informações para outras categorias. No final, trabalhamos com 210 pacientes com batimentos anotados nas classes normal, PAC ou PVC.\n",
    "\n",
    "Os passos de pré-processamento seguiram procedimentos semelhantes aos usados no Banco de Dados Europeu ST-T. Dividimos os pacientes em conjuntos de treinamento e teste, garantindo que cada paciente contribuísse apenas com batimentos de uma única classe. Além disso, descartamos os dois primeiros e os dois últimos batimentos de cada gravação. Após esse processo, obtivemos um conjunto com 168 pacientes para treinamento, com 2.000 batimentos por classe, e 42 pacientes para teste, com 500 batimentos por classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados e Discussões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
